# :house: 캐글 집값 예측 데이터 분석 :house:  
- - -
<h1>Intro</h1> 

- - -
- - -
**캐글 집값 예측 대회 데이터 분석** 내용을 정리한 레포입니다.  
대주제는 캐글 스터디에서 진행하나, 각자 분석은 따로하기 때문에 개인적으로 저장소를 만들어 관리합니다.  
여러 팀원의 insight를 반영해보고, 궁금한 것이 있으면 팀원과 상의해서 결론을 도출하거나 현재 진행하고 있는 엘리스 AI 트랙의 데이터 분석 코치님인 윤치영 코치님에게 자문을 구합니다.
- - -

- 크게 데이터 EDA / 데이터 Feature Engineering / 모델링으로 구성되어 있습니다.
- 각 파일은 google colab 환경에서 개발을 진행했고, 파일마다 상세한 주석과 정리를 수행했습니다.
- 데이터 분석 코치님인 윤치영 코치님과의 오피스아워 내용을 아래에 정리하겠습니다.

- - -

<h3>데이터 EDA</h3>

<h5>house_price_EDA.ipynb</h5>

- imports, settings, data load  
- data shape, info, describe  
- feature meaning comprehend  
- 변수 탐색  
- 타켓 변수 : SalePrice 분포 확인(왜도, 첨도 확인)  
- 수치형 변수 시각화(상관계수 0.5이상)  
- 다중공선성 처리  
- 상관계수 높은 변수 그래프 분석  
- 범주형 변수 시각화  
- 결측값 확인  
- Train/Test 변수 분포  

<h4>더 해볼만한 EDA</h4>

- 범주형 데이터에서 일자형 데이터들이 SalePrice에 어떤 영향을 미치는지 확인
- 각 변수의 특징들과 Saleprice와의 그래프 분포가 논리적으로 일치하는지 확인
- 유형이 같은 애들을 수치형/범주형 차이 두지말고 그룹핑해서 그래프 확인
- 위 작업을 통해 범주형 데이터들 중 SalePrice와 강한 상관을 보이는 변수 도출

- - -

<h3>데이터 Feature Engineering</h3>
<h5>house_price_feature_Engineering&Modeling.ipynb</h5>

- - -

<h3>모델링</h3>
<h5>house_price_feature_Engineering&Modeling.ipynb</h5>

- - -

<h2>오피스아워<h2>
  
**2022/04/28 (목) 오피스아워**

### 1. SalePrice에 log 변환해서 만든 변수를 어떻게 이용할지? 그게 유의미한지 궁금합니다!  
타켓 변수인 SalePrice의 분포를 봤는데, 데이터가 정규성을 띄지 않는것을 확인했습니다.  
ML regression 성능을 악화시킬 영향이 있기 때문에 정규분포 형태로 만들어준다고 배웠습니다.

![image](https://user-images.githubusercontent.com/44998798/165826167-54aff684-1047-4750-b4db-6bcc7ab0a5e4.png)


![image](https://user-images.githubusercontent.com/44998798/165827232-52b4929e-0bc9-42d8-812d-05f20c280c48.png)



그래서 np.log1p 변환을 통해서 정규분포를 만들고 SalePrice_Log 라는 새로운 변수에 변환된 값을 저장했습니다.

![image](https://user-images.githubusercontent.com/44998798/165827388-93e633ae-bf2c-4ae6-8fca-97fbc81ec117.png)


![image](https://user-images.githubusercontent.com/44998798/165827408-b8e9f629-cbef-498d-b806-a84d19989523.png)


그런데 모델링할 때 아래와 같은 그림을 보면 SalePrice_Log 값을 y_train으로 split 한 후 모델링 하고 모델이 만들어지면, test 데이터에 대해 predict를 진행하는데 나온 결과값(saleprice)가 log가 취한 형태로 되어있을거라 판단됩니다.   
그러면 다시 역변환을 진행해야 하는 걸까요?? 그러면 의미가 없는게 아닌가 의구심이 듭니다!!

![image](https://user-images.githubusercontent.com/44998798/165827463-0faaf653-7ac1-4718-83ff-fd158a5b48c6.png)


### 1번에 대한 코치님의 답변
log 변환은 컴퓨터를 속이기 위한 작업이라 생각하시면 쉬울듯합니다.
모델은 가정에 맞는 환경에서만 옳은 결과를 도출해내기 때문에, 해당 가정에 맞는 값을 넣고, 결과를 얻는 것이죠.
이때 log 변환을 하였기 때문에 최종 결과는 역변환을 하는 것이 맞습니다.


### 2. 많은 피처들이 존재하는 상황에서는 이상적인 이상치 탐색과 제거하는 방법은 어떤게 있을까요? 그리고 이상치를 제거하는 것이 항상 좋을까요 ?

![image](https://user-images.githubusercontent.com/44998798/165827856-f9388d2f-b93a-41a6-b3cf-a9c186040b1d.png)

제가 알고 있는 방식으로는 IQR, 모든 피처들에 대해서 saleprice와 그래프를 그려서 판단/제거, Isolation Forest(자세하게는 잘 모름) 입니다.  


### 2번에 대한 코치님의 답변
이상치 제거 방식은 정말 많고 상황에 따라 다릅니다. 단순히 drop 하는 경우도 있고, max와 min을 설정하여 변경하기도 합니다.  
이상치제거는 항상 옳지 않습니다.   
regression이라고 가정을 한다면, 만약 IQR기반, 이상치를 제거 전, 후의 베타값의 차이가 많이 난다면 제거하는 것이 유의미 하지 않은 것이고, 차이가 별로 없다면 단순 이상치로 noise만 생성하는 것이므로 제거하는 것이 맞습니다.    
베타값은 Y= b0 + b1x+ e에서 b1을 의미합니다.
기울기,벡터등등 여러가지 이름이 있죠. 얼마나 변화해야 의미가있는가는 분석가의 판단에 따릅니다.


### 3. 상관계수가 특정 계수 이상인 변수들을 모델링에 사용한다고 가정했을 때, 그 이하인 변수들은 다 제거하는게 맞는건가요 ?  
(예를 들면 0.39와 0.41 계수를 가진 변수들의 경우 고작 0.2차이지만 0.39의 변수는 삭제가 되는게 맞는지)  
찾아본결과 대체적으로 아래 그림과 같이 판단한다고 하더라구요!

![image](https://user-images.githubusercontent.com/44998798/165828379-80402a2b-15c6-49e8-8cbe-b876bd256221.png)


### 3번에 대한 코치님의 답변
상관계수로 상관정도를 파악하는 기준은 교수님, 분석가마다 조금씩 다릅니다.  
코치님 경험상으로는 0.4-0.5가 되지 않는 변수들은 drop시키고, 그 이상되는 변수들은 유의미하게 사용합니다.



### 4. target인 saleprice와 상관계수가 0.5 이상인 변수들에 대해 corr_heatmap을 그렸는데, 다중공선성 변수들에 대한 처리가 궁금합니다. 

![image](https://user-images.githubusercontent.com/44998798/165829074-bb74cd2f-f13d-4d6f-b393-581947f90326.png)

다중공선성이 주로 상관계수가 0.7이상일 때 나타난다고 알고 있습니다.  
현재 상태
1. 1stFlrSF(0.61)-1층 평방피트 / TotalBsmtSF(0.61)-지하 총 평방피트  --------------> 0.82(두 변수의 상관계수)

2. GrLivArea(0.71)-지상 거실 면적 평방 피트 / TotRmsAbvGra(0.53)-지하층 위의 모든 방 (욕실 제외) -- 0.83(두 변수의 상관계수)

3. GarageYrBit(0.49)-차고 지어진 연도 / YearBuilt(0.52)-건물 지어진 연도 ------> 0.83(두 변수의 상관계수)

4. GarageCars(0.64)-차량 수용 가능 차고 크기 / GarageArea(0.62)-차고 평방피트 ---->  0.88(두 변수의 상관계수)

제가 생각하는 다중공선성 처리는 4가지가 있다고 생각합니다.
1. 둘 중 타겟과의 상관계수가 낮은 변수 삭제
의문점
- 위 1번의 경우에는 상관계수가 같다면 어떤것을 삭제해야 할까요 ?
- 두 변수가 타겟과의 상관계수가 매우 높을 때(0.8 이상) 다중공선성이 일어난다고 해서 누구 하나를 삭제하는 것이 맞는걸까요?

2. 다중공선성 변수들을 하나로 묶어서 처리(정확도가 떨어질수도 있음)
의문점
- 위 4가지 경우에서 1번의 경우 1층 평방피트와 지하 총 평방피트를 더해서 새로운 파생변수를 만들어서 처리해도 될까요 ?
- 3번도 마찬가지로 차고 지어진 연도와 건물 지어진 연도를 더해서 처리해도 될까요 ?
- 그러면 2,4번과 같이 서로 수치(피트와 방의 개수)가 다를때는 어떻게 처리해야 할까요 ?

3. 더미기법 사용(범주형 데이터에 흔히 사용)
- one-hot encoding/binary encoding 등 여러가지가 있는 것으로 아는데, one-hot encoding을 사용하겠습니다

4. 다중공선성이 강하게 나타나는 변수중에 해당 독립변수가 영향을 매우 끼치는 변수면 그냥 두기
- 1번 처리에 대한 제가 생각한 방법인데, 이렇게 판단해도 될까요 ?

결론은 1, 3은 두 변수의 합쳐서 새로운 변수를 만들고, 2와 4는 모든 변수가 유의미하다고 판단해서 그냥 둬도 될까요 ?


### 4번에 대한 코치님의 답변
1. 둘 중 타겟과의 상관계수가 낮은 변수를 삭제하세요.  
같다면 타켓인 SalePrice와의 그래프를 그려서 분포를 확인하고 하나를 삭제하세요.  
두 변수가 타겟과의 상관계수가 매우 높아도 그 둘 중 낮은 상관계수를 가진 변수를 삭제하세요.  

2. 유의미한 특징들에 대해 논리적으로 사칙연산 연산을 적용해서 새로운 파생변수를 만드는 것은 좋은 생각입니다.  
하지만 두 변수가 논리적이지 않는 관계성을 가지는 변수들이라면 고려해봐야 합니다.  

3. 네. 범주형 데이터에 대한 encoding 방법을 찾아보시면 좋을꺼 같습니다.  

4. 다중공선성이 강하게 나타난다면 무조건 하나를 삭제해줘야 합니다.  
따라서 이 방법은 안된다고 말씀드리고 싶습니다.


### 5. 범주형 변수에서 boxplot만 보고 타켓인 saleprice와의 강한/약한 연관성을 판단할 수 있나요 ?? (범주형 변수를 one-hot encoding을 해서 수치형으로 바꾼후 corr_heatmap을 뽑아서 판단하는 것을 제외하고)

![image](https://user-images.githubusercontent.com/44998798/165830461-a1e14c50-0224-4d12-a61a-93c6fbcf1f17.png)


### 5번에 대한 코치님의 답변
boxplot만으로는 확실한 연관성을 알아내기는 어렵습니다. 다만, 일자형 데이터의 특징들이 많다면 연관이 없다고 볼 수 있겠습니다.  
일자형 데이터를 볼 때도 데이터가 1개인지 똑같은 데이터가 여러개인지 파악도 해야합니다.  
그리고, 각 변수의 특징들과 Saleprice와의 그래프 분포가 논리적으로 일치하는지 확인해야 합니다. (좋은 평가의 집 일수록 집 가격이 높다)  
유형이 같은 애들을 수치형/범주형 차이 두지말고 그룹핑해서 그래프를 보면 새로운 인사이트를 얻을 수 있습니다.  
boxplot에서 default인 평균값이 아닌 최소값/최대값으로 그래프를 그려보면 새로운 인사이트를 얻을 수 있습니다.

- - -
